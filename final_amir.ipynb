{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell Identification Using Deep Autoencoder and Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-Introduction\n",
    "In the past few decades, deep learning neural networks have become one of the major tools for biomedical data analysis [1] such as medical images analysis [2] and bioinformatics [3]. Deep learning applications in bioinformatics has rapidly advanced since the early 2000s [3]. With increasing demand of big data analysis, different methods and applications were introduced for data compression which reduces the computation cost of the data analysis. Among such methods, image [4] and audio compression techniques have been widely used for decades [5]. Similar methods have been used to simplify gene expression profile (GEP) for further manipulation [6]. In this study, we focus on deep learning application in DNA sequencing compression using autoencoder.\n",
    "Autoencoders are unsupervised neural networks use machine leaning to compress the given data (encoder) and then generate samples similar to the given data (decoder). Convolutional autoencoders are being used to reduce dimension of input data or eliminate noise from the input data. Usually, nonlinear activation functions are used in autoencoder to decrease data loss during encoding. An autoencoder is able to give a representation of output for each layer. Loss function of autoencoder defines as the distance between decoded data and input data. During training of autoencoders, the loss function will be minimized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-Material and Method\n",
    "### Downloading gene expression profile from NCBI GEO\n",
    "This section parses the raw gene expression data obtained from NCBI website. First, the gene expression file is downloaded from the NCBI GEO ftp link:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GDS1615_full.soft.gz\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "link = 'ftp://ftp.ncbi.nlm.nih.gov/geo/datasets/GDS1nnn/GDS1615/soft/GDS1615_full.soft.gz'\n",
    "file_name = urllib.request.urlretrieve(link, link.split('/')[-1])[0]\n",
    "print(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Input the libraries\n",
    "gzip library is importet to handle compressed file downloaded from the NCBI website. numpy and pandas libraries are imported to manipulate gene expression array and input library is used for constant variables to simplify the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.pyplot import plot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get subset description, subset index and gene expression data\n",
    "The 'data_train_set' function is used to read subset discription, subset type and gene expression values of the compressed file download from NCBI website.  The function then returns three numpy arrays for subset description (sd), subset index (si) and gene expression (ge) table respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_geo(file_name, subset_description):\n",
    "    # Data input dimension to simplify is defined (None => imports all the genes unless number of genes are declared)\n",
    "    data_dim = None\n",
    "    with gzip.open(file_name, 'rt') as f:\n",
    "        #    sd: subset description\n",
    "        #    si: subset id\n",
    "        #    ge: gene expression\n",
    "        sd, si, ge = [], [], []\n",
    "        \n",
    "        #    Obtain subset description\n",
    "        for line in f:\n",
    "            if \"!subset_description\" in line:\n",
    "                sd.append(line.split('=')[1].strip())\n",
    "                \n",
    "            elif \"!subset_sample_id\" in line:\n",
    "                si.append(line.split('=')[1].strip().split(','))\n",
    "                \n",
    "            elif \"!dataset_table_begin\" in line:\n",
    "                break\n",
    "            \n",
    "        subset_number = sum(len(sd) for sd in si)\n",
    "            \n",
    "#        Read the gene info table\n",
    "\n",
    "        for line in f:\n",
    "            if \"!dataset_table_begin\" in line:\n",
    "                break            \n",
    "    \n",
    "            elif \"!dataset_table_end\" in line:\n",
    "                break\n",
    "    \n",
    "            ge.append(line.split()[:2 + subset_number])\n",
    "    \n",
    "    ge = pd.DataFrame(ge)\n",
    "    new_header = ge.iloc[0]\n",
    "    ge.columns = new_header\n",
    "    ge = ge[1:]\n",
    "    \n",
    "    return sd, si, ge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rearrange sd, si and ge arrays and complete parsing\n",
    "Then, sd, si and ge arrays will be used to form a complete dataset with data and labels separated and prepared for further analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_train_test(file_name):\n",
    "    data_dim = None # indicated input data (if it is None it means all the gene expression values will be imported)\n",
    "    #   Reads subsets discribtion, indexes and the whole gene expression data\n",
    "    sd, si, ge = read_geo(file_name, 'all')\n",
    "\n",
    "    #   Separate data from the gene expression table\n",
    "    ge_array = np.array(ge)\n",
    "    d = ge_array[:, 2:].astype(float)\n",
    "\n",
    "    # Convert numpy array to training format for SVM solver\n",
    "    data = []\n",
    "    for i in range(len(d[0,:])):\n",
    "        data.append(d[:data_dim,i])\n",
    "    data = np.array(data)\n",
    "\n",
    "    #   Assign numbers to subset types and make a target vector for classification\n",
    "    labels = []\n",
    "    for i in range(0, len(sd)):\n",
    "        labels.append(len(si[i]) * [i])\n",
    "    \n",
    "    #   Merge the target groups (each type is a list in python, \n",
    "    #   this part merges the parts to have unit target vector)\n",
    "    label_tmp = []\n",
    "    for j in range(len(labels)):\n",
    "        label_tmp += labels[j]\n",
    "    labels = np.array(label_tmp)\n",
    "\n",
    "    # dimension of input gene expression\n",
    "    label_dimension = len(ge_array[0,2:])\n",
    "    labels = labels.reshape((label_dimension,1))\n",
    "\n",
    "\n",
    "    #   This line joins the data and labels as a new 2D array\n",
    "    dataset = np.concatenate((data, labels), axis=1)\n",
    "\n",
    "    #   This part randomly shuffles the data to be ready for training and testing purposes\n",
    "    np.random.shuffle(dataset)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[105.932     26.6538    61.4062   ...   9.10682    1.31412    2.      ]\n",
      " [ 69.0926    14.7126    34.7756   ...   4.72682    0.966992   2.      ]\n",
      " [ 64.713     29.6233    40.1533   ...   2.16422    0.698281   0.      ]\n",
      " ...\n",
      " [ 76.7187    27.5782    61.1081   ...   9.09038    2.06627    1.      ]\n",
      " [105.453     27.6385    25.647    ...   3.64447    2.9912     2.      ]\n",
      " [108.099     28.5333    80.1208   ...   6.51928    1.25663    0.      ]]\n"
     ]
    }
   ],
   "source": [
    "print(data_train_test(file_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f-OBnL4d79LQ"
   },
   "source": [
    "# Autoencoder to compress the gene expression data\n",
    "This following code is to build an autoencoder to compress the raw gene expression vectors and reconstruct them back into the similar gene expression distribution. Goal is to reduce gene expression dimension and simpliofy numerical manipulations needed for SVM classifier to determine which gene expression belongs to which type of cell.\n",
    "### The libraries needed for the analysis\n",
    "- tensorflow which handles the neral network analysis\n",
    "- matbplotlib for visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- keras which is a framework with tensor in backend:\n",
    "\n",
    "    - Input: function creates a placeholder for input variable which is case is one gene expression vector\n",
    "    - Dense: This function builds the network layers with desired number of nodes\n",
    "    - Model: We use this function builds the models for encoder part and autoencoder\n",
    "    - normalize: This function wil be used to normalize the input array before analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.utils import normalize\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here, database will be imported to the code:\n",
    "In this section, we read the data provided in another module which parses the raw gene expression file from the NCBI website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, numpy library will be used for log(2) transformation of the input data before analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input gene expression array is imported (note that we don't import the labels here). Then $log(2)$ transform is applied on the input data and then they were normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset = data_train_test(file_name)\n",
    "data =np.log(dataset[:,:-1]) / np.log(2)\n",
    "data = normalize(data, axis=0, order=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = len(data[0, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "80% of input data is used for training and 20% for testing accuracy of the autoencoder model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n"
     ]
    }
   ],
   "source": [
    "percent_80 = int(len(data[:, 0]) * 0.8)\n",
    "print(percent_80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train = data[:percent_80,:input_size]\n",
    "L_train = dataset[:percent_80, -1]\n",
    "X_test = data [percent_80:,:input_size]\n",
    "L_test = dataset[percent_80:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qyq1OIEm9KcT"
   },
   "source": [
    "### The neural network parameters\n",
    "Starting with learning parameter, batch size which is number of samples passing to the neural network at one time and epoch number determines how many times all the data will be passed through the network. The latent vector dimension is defined which indicates compressed version of the input gene expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I2w4_Pnp8_cx",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "epoch_size = 100\n",
    "batch_size = 1000\n",
    "latent_dim = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The schematic view of the this neural network can be seen in the following figure:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"files\\fig_1.PNG\" height=\"500\" width=\"500\" class=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the neural network layers\n",
    "#### Input layer\n",
    "First, we define the encoder section by defining input values as follows. The input shape will be flattened as a vector with input dimension.\"None\" means there are no data in this input, it is just a place holder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "input_gene_expression = Input(shape=(input_size,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoder layer\n",
    "The encoder layer will connet input layer to the latent vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Amir\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "encoded = Dense(latent_dim, activation='relu')(input_gene_expression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decoder layer\n",
    "Decoder layer is defined same as encoder layer but, it connects latent space to the output layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "decoded = Dense(input_size, activation ='sigmoid')(encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Autoencoder model\n",
    "The autoencoder model is created mapping input data to reconstructed data similar to the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "autoencoder = Model(input_gene_expression, decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoder model\n",
    "Encoder model is created to show the latent vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "encoder = Model(input_gene_expression, encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function definition\n",
    "Loss function of variational autoencoder is defined as the distance between input and output (reconstructed input) user mean squared error dunction:\n",
    "\n",
    "Mean Squared Error $= \\frac{1}{n}\\sum_{i=1}^n.(X_i^2 - \\hat{X_i^2})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling the models\n",
    "The optimizer \"adam\" is then used to minimize the MSE function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the autoencoder model\n",
    "Network dimensions, batch and epoch sizes and training and testing datasets are used to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "class PlotLosses(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.i = 0\n",
    "        self.x = []\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        \n",
    "        self.fig = plt.figure()\n",
    "        \n",
    "        self.logs = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        self.logs.append(logs)\n",
    "        self.x.append(self.i)\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        self.i += 1\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        plt.plot(self.x, self.losses, label=\"loss\")\n",
    "#         plt.plot(self.x, self.val_losses, label=\"val_loss\")\n",
    "        plt.xlabel('Epoch number')\n",
    "        plt.ylabel('MSE value')\n",
    "        plt.legend()\n",
    "        plt.show();\n",
    "        \n",
    "plot_losses = PlotLosses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24d9dc9f710>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(X_train, X_train, epochs=epoch_size, batch_size=batch_size, \\\n",
    "                shuffle=True, callbacks=[PlotLosses()], validation_data=(X_test, X_test), verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: (To avoid overfitting)\n",
    "According to the loss function graph, when the loss function value converges, training process is interrupted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-Results and Discussion\n",
    "In this section the first five values of the first randomly picked original gene expression is shown. And the latent vector representing that egpression is represented. Then the corresping reconstruction of gene expression is shown to compare with the original raw input. As it can be seen, the latent vector's dimension is reduced and duruing decoding, part of information is lost. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 values of the raw gene expression data:\n",
      " [0.65889387 0.61537757 0.49839267 0.64802145 0.63181147 0.54529577\n",
      " 0.61839145 0.26945971 0.60349601 0.71809828] \n",
      "\n",
      "Latent vector:\n",
      " [-0.       -0.       -0.       -0.       -0.       -0.       -0.\n",
      " -0.       -0.       -0.       -0.       -0.       -0.       -0.\n",
      " -0.       -0.       -0.       -0.       28.093348 -0.       -0.\n",
      " -0.       -0.       -0.       -0.       -0.       -0.       -0.\n",
      " -0.       -0.      ] \n",
      "\n",
      "First 10 values of the reconstructed gene expression data:\n",
      " [0.57747495 0.56795114 0.5582078  0.57978284 0.5137652  0.5750063\n",
      " 0.56749773 0.45039552 0.57285774 0.5429579 ]\n"
     ]
    }
   ],
   "source": [
    "latent = encoder.predict(X_test)\n",
    "reconstructed = autoencoder.predict(X_test)\n",
    "i = 1\n",
    "\n",
    "print('First 10 values of the raw gene expression data:\\n', X_test[i][:10], '\\n')\n",
    "print('Latent vector:\\n', latent[i], '\\n')\n",
    "print('First 10 values of the reconstructed gene expression data:\\n', reconstructed[i][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine for Cell Type Classiffication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM method in 'sklean' python module will be used for SVM classification during this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function will classify cell type. The input is the reconstructed gene expression vector obtained from the previous section and the is a corresponding subset type. It classifier is trained with 80% of the data and the 20% of rest of the data is for validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cell_classifier(input):\n",
    "    model = svm.SVC(gamma=0.0001, C=10000.)\n",
    "    model.fit(X_train, L_train)\n",
    "    output = model.predict(input)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison\n",
    "The following two vectors show the original and reconstructed cell types. \n",
    "### Test labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 2. 0. 2. 2. 2. 2. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 1. 2. 2. 2. 1. 0. 0.\n",
      " 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "print(cell_classifier(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicted labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 2. 0. 2. 1. 2. 2. 0. 0. 0. 2. 2. 0. 2. 2. 2. 2. 1. 2. 2. 2. 1. 0. 2.\n",
      " 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(L_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy\n",
    "Accuracy of code is evaluated using the percentage of misclassification made by the SMV solver:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 84.61538461538461 %\n"
     ]
    }
   ],
   "source": [
    "match_number = 0\n",
    "for i in range(len(L_test)):\n",
    "    if cell_classifier(X_test)[i] == L_test[i]:\n",
    "        match_number += 1\n",
    "acc = match_number / len(L_test)\n",
    "print('Accuracy: {}'.format(acc * 100), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
